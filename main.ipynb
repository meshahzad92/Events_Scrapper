{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from 'd:\\\\Desktop\\\\Events_Scrapper\\\\functions.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "from functions import *\n",
    "import functions\n",
    "\n",
    "api_key = \"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\"\n",
    "\n",
    "# Reload the functions module each time it is modified\n",
    "importlib.reload(functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n",
      "Data successfully added to CSV!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def append_to_csv(file_name=\"umair_done_updated_not_cleaned_feb25.csv\"):\n",
    "    \"\"\"\n",
    "    Appends manually entered event \n",
    "    data to a CSV file.\n",
    "    If the file doesn't exist, it creates one with the appropriate headers.\n",
    "\n",
    "    :param file_name: Name of the CSV file (default: umair_done.csv)\n",
    "    \"\"\"\n",
    "    # Updated columns list to include the new columns (Category and Charity)\n",
    "    columns = [\"event_name\", \"date_and_time\", \"description\", \"location\", \"cost\", \"event_url\", \"category\", \"charity\", \"organization_link\"]\n",
    "\n",
    "    # Check if the file exists, if not, create it with headers\n",
    "    file_exists = os.path.isfile(file_name)\n",
    "\n",
    "    with open(file_name, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write headers if the file is new (only if file doesn't already exist)\n",
    "        if not file_exists:\n",
    "            writer.writerow(columns)\n",
    "\n",
    "        # Prompt user to enter values manually\n",
    "        data = []\n",
    "        \n",
    "        for col in columns:\n",
    "            value = input(f\"Enter {col.replace('_', ' ').title()}: \")\n",
    "            \n",
    "            if col == 'date_and_time':\n",
    "                # Apply any formatting logic here for date and time, if needed\n",
    "                # value = format_date_and_time(value)  # Example placeholder, replace with actual function if necessary\n",
    "                pass\n",
    "            data.append(value)\n",
    "\n",
    "        # Append the new row\n",
    "        writer.writerow(data)\n",
    "        print(\"Data successfully added to CSV!\")\n",
    "\n",
    "# Run the function in a loop\n",
    "while True:\n",
    "    append_to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>date_and_time</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>cost</th>\n",
       "      <th>event_url</th>\n",
       "      <th>category</th>\n",
       "      <th>charity</th>\n",
       "      <th>organization_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Better Sleep for Kids</td>\n",
       "      <td>Wednesday, February 26, 2025 6:30 p.m.  8:00 p.m.</td>\n",
       "      <td>Clinical Psychologist, Dr. Jessica Engle, will...</td>\n",
       "      <td>Inperson/Online</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://www.ldayukon.com/events/better-sleep-f...</td>\n",
       "      <td>Disabilities and Accessibility Services</td>\n",
       "      <td>Learning Disabilities Association Of Yukon</td>\n",
       "      <td>WWW.LDAYUKON.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snowshoe Fest 2025</td>\n",
       "      <td>Saturday, March 8, 2025 1:00 p.m.  3:30 p.m.</td>\n",
       "      <td>At Biathlon Yukon. Details coming soon!</td>\n",
       "      <td>Biathlon Yukon</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://www.ldayukon.com/events/snowshoe-fest-...</td>\n",
       "      <td>Disabilities and Accessibility Services</td>\n",
       "      <td>Learning Disabilities Association Of Yukon</td>\n",
       "      <td>WWW.LDAYUKON.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Awards Gathering</td>\n",
       "      <td>Tuesday, May 28, 2024 6:30 p.m.  7:30 p.m.</td>\n",
       "      <td>LDAY’s annual celebration of our hard working ...</td>\n",
       "      <td>Whitehorse Public Library</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://www.ldayukon.com/events/awards-gathering</td>\n",
       "      <td>Disabilities and Accessibility Services</td>\n",
       "      <td>Learning Disabilities Association Of Yukon</td>\n",
       "      <td>WWW.LDAYUKON.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDAY AGM 2023</td>\n",
       "      <td>Monday, July 24, 2023 5:00 p.m.  7:00 p.m.</td>\n",
       "      <td>The LDAY Centre for Learning AGM will be Monda...</td>\n",
       "      <td>Online</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://www.ldayukon.com/events/lday-agm-2023</td>\n",
       "      <td>Disabilities and Accessibility Services</td>\n",
       "      <td>Learning Disabilities Association Of Yukon</td>\n",
       "      <td>WWW.LDAYUKON.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Welcome to Your Child's AHDH Brain</td>\n",
       "      <td>Monday, May 8, 2023 6:30 p.m.  8:00 p.m.</td>\n",
       "      <td>Join Aaron Bailey as he provides a glimpse int...</td>\n",
       "      <td>Yukon University, Lecture Hall A2206 500 Unive...</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://www.ldayukon.com/events/o5c7d9ap95lin2...</td>\n",
       "      <td>Disabilities and Accessibility Services</td>\n",
       "      <td>Learning Disabilities Association Of Yukon</td>\n",
       "      <td>WWW.LDAYUKON.COM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           event_name  \\\n",
       "0               Better Sleep for Kids   \n",
       "1                  Snowshoe Fest 2025   \n",
       "2                    Awards Gathering   \n",
       "3                       LDAY AGM 2023   \n",
       "4  Welcome to Your Child's AHDH Brain   \n",
       "\n",
       "                                       date_and_time  \\\n",
       "0  Wednesday, February 26, 2025 6:30 p.m.  8:00 p.m.   \n",
       "1       Saturday, March 8, 2025 1:00 p.m.  3:30 p.m.   \n",
       "2         Tuesday, May 28, 2024 6:30 p.m.  7:30 p.m.   \n",
       "3         Monday, July 24, 2023 5:00 p.m.  7:00 p.m.   \n",
       "4           Monday, May 8, 2023 6:30 p.m.  8:00 p.m.   \n",
       "\n",
       "                                         description  \\\n",
       "0  Clinical Psychologist, Dr. Jessica Engle, will...   \n",
       "1            At Biathlon Yukon. Details coming soon!   \n",
       "2  LDAY’s annual celebration of our hard working ...   \n",
       "3  The LDAY Centre for Learning AGM will be Monda...   \n",
       "4  Join Aaron Bailey as he provides a glimpse int...   \n",
       "\n",
       "                                            location           cost  \\\n",
       "0                                    Inperson/Online  Not Available   \n",
       "1                                     Biathlon Yukon  Not Available   \n",
       "2                         Whitehorse Public Library   Not Available   \n",
       "3                                             Online  Not Available   \n",
       "4  Yukon University, Lecture Hall A2206 500 Unive...  Not Available   \n",
       "\n",
       "                                           event_url  \\\n",
       "0  https://www.ldayukon.com/events/better-sleep-f...   \n",
       "1  https://www.ldayukon.com/events/snowshoe-fest-...   \n",
       "2   https://www.ldayukon.com/events/awards-gathering   \n",
       "3      https://www.ldayukon.com/events/lday-agm-2023   \n",
       "4  https://www.ldayukon.com/events/o5c7d9ap95lin2...   \n",
       "\n",
       "                                  category  \\\n",
       "0  Disabilities and Accessibility Services   \n",
       "1  Disabilities and Accessibility Services   \n",
       "2  Disabilities and Accessibility Services   \n",
       "3  Disabilities and Accessibility Services   \n",
       "4  Disabilities and Accessibility Services   \n",
       "\n",
       "                                      charity organization_link  \n",
       "0  Learning Disabilities Association Of Yukon  WWW.LDAYUKON.COM  \n",
       "1  Learning Disabilities Association Of Yukon  WWW.LDAYUKON.COM  \n",
       "2  Learning Disabilities Association Of Yukon  WWW.LDAYUKON.COM  \n",
       "3  Learning Disabilities Association Of Yukon  WWW.LDAYUKON.COM  \n",
       "4  Learning Disabilities Association Of Yukon  WWW.LDAYUKON.COM  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"umair_done_updated.csv\")\n",
    "\n",
    "# Function to standardize the date and time formats\n",
    "def standardize_datetime(date_str):\n",
    "    # Case 1: Full date with day of the week and time range (e.g., \"Wednesday, February 26, 2025 6:30 p.m. 8:00 p.m.\")\n",
    "    match = re.match(r\"(\\w+day), (\\w+ \\w+ \\d{1,2}, \\d{4}) (\\d{1,2}:\\d{2} [a|p]\\.m\\.) (\\d{1,2}:\\d{2} [a|p]\\.m\\.)\", date_str)\n",
    "    if match:\n",
    "        date = datetime.strptime(match.group(2), \"%B %d, %Y\")\n",
    "        start_time = datetime.strptime(match.group(3), \"%I:%M %p\").time()\n",
    "        end_time = datetime.strptime(match.group(4), \"%I:%M %p\").time()\n",
    "        return f\"{date.strftime('%Y-%m-%d')} {start_time} - {end_time}\"\n",
    "\n",
    "    # Case 2: Time range with time zone (e.g., \"3:30 pm Eastern Time | 2 hours Date: February 25, 2025\")\n",
    "    match = re.match(r\"(\\d{1,2}:\\d{2} [a|p]\\.m\\.) (Eastern Time|ET|GMT) \\|? \\d?[\\w\\s]+ Date: (\\w+ \\d{1,2}, \\d{4})\", date_str)\n",
    "    if match:\n",
    "        date = datetime.strptime(match.group(3), \"%B %d, %Y\")\n",
    "        time = datetime.strptime(match.group(1), \"%I:%M %p\").time()\n",
    "        return f\"{date.strftime('%Y-%m-%d')} {time}\"\n",
    "\n",
    "    # Case 3: Date range (e.g., \"September 1, 2024 - August 31, 2025\")\n",
    "    match = re.match(r\"(\\w+ \\d{1,2}, \\d{4}) - (\\w+ \\d{1,2}, \\d{4})\", date_str)\n",
    "    if match:\n",
    "        start_date = datetime.strptime(match.group(1), \"%B %d, %Y\")\n",
    "        end_date = datetime.strptime(match.group(2), \"%B %d, %Y\")\n",
    "        return f\"{start_date.strftime('%Y-%m-%d')} - {end_date.strftime('%Y-%m-%d')}\"\n",
    "\n",
    "    # Case 4: Date without time (e.g., \"June 7, 2025\")\n",
    "    match = re.match(r\"(\\w+ \\d{1,2}, \\d{4})\", date_str)\n",
    "    if match:\n",
    "        date = datetime.strptime(match.group(1), \"%B %d, %Y\")\n",
    "        return f\"{date.strftime('%Y-%m-%d')}\"\n",
    "\n",
    "    # Case 5: Short date-time range (e.g., \"07/Jun/2025 10:00 am - 07/Jun/2025 1:00 pm\")\n",
    "    match = re.match(r\"(\\d{2}/\\w{3}/\\d{4} \\d{1,2}:\\d{2} [a|p]\\.m.) - (\\d{2}/\\w{3}/\\d{4} \\d{1,2}:\\d{2} [a|p]\\.m.)\", date_str)\n",
    "    if match:\n",
    "        start_time = datetime.strptime(match.group(1), \"%d/%b/%Y %I:%M %p\")\n",
    "        end_time = datetime.strptime(match.group(2), \"%d/%b/%Y %I:%M %p\")\n",
    "        return f\"{start_time.strftime('%Y-%m-%d %H:%M')} - {end_time.strftime('%Y-%m-%d %H:%M')}\"\n",
    "\n",
    "    # Default case: if no match, return the original string\n",
    "    return date_str\n",
    "\n",
    "\n",
    "\n",
    "# Display the cleaned-up data\n",
    "# df['date_and_time']=df['date_and_time'].apply(format_date_and_time)\n",
    "df['cost']=df['cost'].apply(format_cost)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Processed_date.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing date: Wednesday, February 26, 2025 6:30 p.m.  8:00 p.m.\n",
      "Error processing date: Saturday, March 8, 2025 1:00 p.m.  3:30 p.m.\n",
      "Error processing date: Tuesday, May 28, 2024 6:30 p.m.  7:30 p.m.\n",
      "Error processing date: Monday, July 24, 2023 5:00 p.m.  7:00 p.m.\n",
      "Error processing date: Monday, May 8, 2023 6:30 p.m.  8:00 p.m.\n",
      "Error processing date:  September 1, 2024 - August 31, 2025\n",
      "Error processing date:  Live Wednesdays at 1 p.m. E.T. : September 25, 2024 - March 7, 2025\n",
      "Error processing date: Weekly, from February 21 to April 24 : February 21, 2025 - April 24, 2025\n",
      "Error processing date: 5:30 - 6:30 p.m. ET\n",
      "Error processing date: Time: 1 p.m. ET Date: February 25, 2025\n",
      "Error processing date: Time: 1 p.m. ET Date: March 4, 2025\n",
      "Error processing date:  1 p.m. ET Date: March 6, 2025\n",
      "Error processing date: 4 - 5 p.m. ET Date: March 11, 2025\n",
      "Error processing date: 1 p.m. ET Date: March 11, 2025\n",
      "Error processing date: 9 a.m. to 2 p.m. (ET) Date: May 6, 2025\n",
      "Error processing date: 1 p.m. ET Date: April 1, 2025 - April 22, 2025\n",
      "Error processing date: 5:30 - 6:30 p.m. ET Date: March 18, 2025\n",
      "Error processing date: 1 p.m. ET Date: March 25, 2025\n",
      "Error processing date: Saturday, April 5, 2025\n",
      "Error processing date: Friday, April 25 - Sunday, April 27, 2025\n",
      "Error processing date: 07/Jun/2025 10:00 am - 07/Jun/2025 1:00 pm\n",
      "Error processing date: 11/May/2025 8:00 am - 11/May/2025 12:00 pm\n",
      "Error processing date: 04/May/2025 12:00 am - 04/May/2025 11:59 pm\n",
      "Error processing date: 08/Feb/2025 12:00 am - 08/Feb/2025 11:59 pm\n",
      "Error processing date: Wednesday April 15, 2025  Time: 5:00 pm - 8:00 pm\n"
     ]
    }
   ],
   "source": [
    "def standardize_date(date_str):\n",
    "    try:\n",
    "        # Handle ranges like 'From $10 to $20'\n",
    "        if \" - \" in date_str:\n",
    "            parts = date_str.split(\" - \")\n",
    "            start_date = datetime.strptime(parts[0], \"%B %d, %Y\")\n",
    "            end_date = datetime.strptime(parts[1], \"%B %d, %Y\")\n",
    "            return [start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")]\n",
    "        elif \" p.m.\" in date_str or \" a.m.\" in date_str:\n",
    "            # Handle specific times\n",
    "            date_time = datetime.strptime(date_str, \"%A, %B %d, %Y %I:%M %p\")\n",
    "            return date_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        elif \" ET\" in date_str:\n",
    "            # Handle timezones\n",
    "            date_time = datetime.strptime(date_str, \"%I:%M %p ET\")\n",
    "            return date_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        elif \"Time\" in date_str:\n",
    "            parts = date_str.split(\"Date: \")\n",
    "            date_time = datetime.strptime(parts[1], \"%B %d, %Y\")\n",
    "            return date_time.strftime(\"%Y-%m-%d\")\n",
    "        else:\n",
    "            date_time = datetime.strptime(date_str, \"%B %d, %Y\")\n",
    "            return date_time.strftime(\"%Y-%m-%d\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing date: {date_str}\")\n",
    "        return None\n",
    "\n",
    "df['date_and_time']=df['date_and_time'].apply(standardize_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (39) does not match length of index (40)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 44\u001b[0m\n\u001b[0;32m      1\u001b[0m standardized_dates \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2025-02-26 18:30:00-20:00:00\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2025-03-08 13:00:00-15:30:00\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2025-04-15 17:00:00-20:00:00\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Time range\u001b[39;00m\n\u001b[0;32m     41\u001b[0m ]\n\u001b[0;32m     43\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mumair_done_updated.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate_and_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m=\u001b[39mstandardized_dates\n",
      "File \u001b[1;32md:\\Desktop\\Events_Scrapper\\env\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Desktop\\Events_Scrapper\\env\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4530\u001b[0m     ):\n\u001b[0;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32md:\\Desktop\\Events_Scrapper\\env\\Lib\\site-packages\\pandas\\core\\frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[0;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[0;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[1;32md:\\Desktop\\Events_Scrapper\\env\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (39) does not match length of index (40)"
     ]
    }
   ],
   "source": [
    "standardized_dates = [\n",
    "    \"2025-02-26 18:30:00-20:00:00\",\n",
    "    \"2025-03-08 13:00:00-15:30:00\",\n",
    "    \"2024-05-28 18:30:00-19:30:00\",\n",
    "    \"2023-07-24 17:00:00-19:00:00\",\n",
    "    \"2023-05-08 18:30:00-20:00:00\",\n",
    "    \"2024-09-01-2025-08-31\",  # Date range\n",
    "    \"2024-09-25\",  # Extracted from Live Wednesdays\n",
    "    \"2024-11-01-2025-06-01\",  # Date range\n",
    "    \"2024-11-01-2025-06-01\",  # Date range\n",
    "    \"2024-12-02-2025-05-27\",  # Date range\n",
    "    \"2025-02-21-2025-04-24\",  # Date range\n",
    "    \"2025-02-21 17:30:00-18:30:00\",  # Time range\n",
    "    \"2025-02-25 13:00:00\",  # Extracted from Time: 1 p.m.\n",
    "    \"2025-02-25 15:30:00\",  # Extracted from Eastern Time\n",
    "    \"2025-03-04 13:00:00\",  # Extracted from Time\n",
    "    \"2025-03-05 20:00:00\",  # Extracted from Time\n",
    "    \"2025-03-06 13:00:00\",  # Extracted from Time\n",
    "    \"2025-03-11 16:00:00-17:00:00\",  # Time range\n",
    "    \"2025-03-11 13:00:00\",  # Extracted from Date\n",
    "    \"2025-03-20 19:30:00\",  # Extracted from Eastern Time\n",
    "    \"2025-05-21 19:30:00\",  # Extracted from Date\n",
    "    \"2025-05-08 15:30:00\",  # Extracted from Date\n",
    "    \"2025-04-10 15:30:00\",  # Extracted from Date\n",
    "    \"2025-05-06 09:00:00-14:00:00\",  # Time range\n",
    "    \"2025-03-21 13:00:00\",  # Extracted from Date\n",
    "    \"2025-03-25 13:00:00\",  # Extracted from Date\n",
    "    \"2025-03-25 11:15:00\",  # Extracted from Date\n",
    "    \"2025-03-18 17:30:00-18:30:00\",  # Time range\n",
    "    \"2025-03-20 15:30:00\",  # Extracted from Date\n",
    "    \"2025-03-25 15:00:00\",  # Extracted from Date\n",
    "    \"2025-03-25 13:00:00\",  # Extracted from Date\n",
    "    \"2025-04-05\",  # Saturday\n",
    "    \"2025-04-25-2025-04-27\",  # Date range\n",
    "    \"2025-06-07 10:00:00-13:00:00\",  # Time range\n",
    "    \"2025-05-11 08:00:00-12:00:00\",  # Time range\n",
    "    \"2025-05-04 00:00:00-23:59:59\",  # Time range\n",
    "    \"2025-02-08 00:00:00-23:59:59\",  # Time range\n",
    "    \"2025-06-07\",  # Just date\n",
    "    \"2025-04-15 17:00:00-20:00:00\"  # Time range\n",
    "]\n",
    "\n",
    "df=pd.read_csv(\"umair_done_updated.csv\")\n",
    "df['date_and_time']=standardized_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"umair_done_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\n",
    "    \"26/2/2025 18:30-20:00\",\n",
    "    \"8/3/2025 13:00-15:30\",\n",
    "    \"28/5/2024 18:30-19:30\",\n",
    "    \"24/7/2023 17:00-19:00\",\n",
    "    \"8/5/2023 18:30-20:00\",\n",
    "    \"1/9/2024 - 31/8/2025\",\n",
    "    \"25/9/2024 13:00\",\n",
    "    \"1/11/2024 - 1/6/2025\",\n",
    "    \"1/11/2024 - 1/6/2025\",\n",
    "    \"2/12/2024 - 27/5/2025\",\n",
    "    \"21/2/2025 - 24/4/2025\",\n",
    "    \"17:30-18:30\",\n",
    "    \"25/2/2025 13:00\",\n",
    "    \"27/2/2025 15:30-17:30\",\n",
    "    \"4/3/2025 13:00\",\n",
    "    \"5/3/2025 20:00\",\n",
    "    \"6/3/2025 13:00\",\n",
    "    \"11/3/2025 16:00-17:00\",\n",
    "    \"11/3/2025 13:00\",\n",
    "    \"12/3/2025 19:30-20:00\",\n",
    "    \"21/5/2025 19:30-20:00\",\n",
    "    \"8/5/2025 15:30-17:30\",\n",
    "    \"10/4/2025 15:30-17:30\",\n",
    "    \"6/5/2025 09:00-14:00\",\n",
    "    \"13/3/2025 19:30-20:00\",\n",
    "    \"1/4/2025 - 22/4/2025\",\n",
    "    \"25/3/2025 13:00\",\n",
    "    \"25/3/2025 11:15\",\n",
    "    \"18/3/2025 17:30-18:30\",\n",
    "    \"20/3/2025 15:30-17:30\",\n",
    "    \"25/3/2025 15:00\",\n",
    "    \"25/3/2025 13:00\",\n",
    "    \"5/4/2025\",\n",
    "    \"25/4/2025 - 27/4/2025\",\n",
    "    \"7/6/2025 10:00-13:00\",\n",
    "    \"11/5/2025 08:00-12:00\",\n",
    "    \"4/5/2025 00:00-23:59\",\n",
    "    \"8/2/2025 00:00-23:59\",\n",
    "    \"7/6/2025\",\n",
    "    \"15/4/2025 17:00-20:00\"\n",
    "]\n",
    "\n",
    "df[\"date_and_time\"] = dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"umair_done_updated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down how AI works.  It's a vast field, so I'll try to give you a good overview without getting *too* technical. Think of it as a multi-layered explanation, starting with the big picture and then digging a little deeper.\n",
      "\n",
      "**1. The Basic Idea: Mimicking Intelligence**\n",
      "\n",
      "At its core, Artificial Intelligence (AI) is about creating machines that can perform tasks that typically require human intelligence.  This includes things like:\n",
      "\n",
      "*   **Learning:** Acquiring information and rules for using the information.\n",
      "*   **Reasoning:** Using rules to reach conclusions.\n",
      "*   **Problem-solving:** Figuring out how to achieve a goal.\n",
      "*   **Perception:** Understanding the world through senses (like vision, hearing, etc.).\n",
      "*   **Language Understanding:** Comprehending and generating human language.\n",
      "\n",
      "**2.  How AI Achieves \"Intelligence\":  Algorithms and Data**\n",
      "\n",
      "AI achieves these abilities through a combination of **algorithms** and **data**:\n",
      "\n",
      "*   **Algorithms:** These are sets of rules or instructions that the AI follows to perform a task.  Think of them as recipes.  The algorithm tells the AI what to do with the data it receives.\n",
      "*   **Data:** This is the information the AI uses to learn and make decisions.  It can be anything from images and text to numbers and sounds. The more relevant and high-quality data the AI has, the better it can learn.\n",
      "\n",
      "**3. Types of AI:  A Broad Categorization**\n",
      "\n",
      "AI can be broadly categorized based on its capabilities:\n",
      "\n",
      "*   **Narrow or Weak AI:**  Designed for a specific task.  This is the type of AI we see most often today. Examples:\n",
      "    *   Spam filters\n",
      "    *   Recommendation systems (like Netflix or Amazon)\n",
      "    *   Voice assistants (like Siri or Alexa)\n",
      "    *   Image recognition software\n",
      "*   **General or Strong AI:**  Hypothetical AI that possesses human-level intelligence.  It could understand, learn, and apply knowledge across a wide range of tasks.  This doesn't exist yet.\n",
      "*   **Super AI:**  Hypothetical AI that surpasses human intelligence in all aspects.  This is purely theoretical and raises many ethical concerns.\n",
      "\n",
      "**4. Key Techniques in AI:  A Deeper Dive**\n",
      "\n",
      "Here are some of the most important techniques used in AI:\n",
      "\n",
      "*   **Machine Learning (ML):** This is a *subset* of AI where the AI learns from data without being explicitly programmed. Instead of writing specific rules for every situation, the AI identifies patterns in the data and adjusts its behavior accordingly.\n",
      "\n",
      "    *   **Supervised Learning:** The AI is trained on labeled data, meaning the data is already categorized or has the correct answer provided.  For example, to train an AI to identify cats in images, you would feed it a dataset of images that are labeled as either \"cat\" or \"not cat.\"  The AI learns to associate features in the images with the correct label.\n",
      "    *   **Unsupervised Learning:** The AI is trained on unlabeled data.  It must find patterns and structures in the data on its own.  For example, you could feed an AI a large dataset of customer data and it might identify different customer segments based on their purchasing behavior.\n",
      "    *   **Reinforcement Learning:** The AI learns by trial and error. It interacts with an environment and receives rewards or penalties for its actions. The AI tries to maximize its rewards over time.  This is used in things like training AI to play games (like Go) or control robots.\n",
      "\n",
      "*   **Deep Learning (DL):**  This is a *subset* of Machine Learning that uses artificial neural networks with multiple layers (hence \"deep\"). These networks are inspired by the structure of the human brain. Deep learning is particularly good at processing complex data like images, audio, and text.\n",
      "\n",
      "    *   **Neural Networks:**  These are interconnected nodes (artificial neurons) organized in layers.  Each connection between neurons has a weight associated with it.  The AI learns by adjusting these weights to improve its performance.  Deep Learning uses networks with many layers, allowing them to learn very complex patterns.\n",
      "    *   **Convolutional Neural Networks (CNNs):**  Specifically designed for processing images.  They use convolutional layers to extract features from images, such as edges, textures, and shapes.\n",
      "    *   **Recurrent Neural Networks (RNNs):**  Designed for processing sequential data, like text or time series. They have feedback loops that allow them to remember past information.  Variants like LSTMs (Long Short-Term Memory) are particularly good at handling long-range dependencies in sequences.\n",
      "    *   **Transformers:**  A more recent architecture that has revolutionized natural language processing.  They use a mechanism called \"attention\" to weigh the importance of different parts of the input sequence.  Large Language Models (LLMs) like GPT-3 and BERT are based on the Transformer architecture.\n",
      "\n",
      "*   **Natural Language Processing (NLP):**  This focuses on enabling computers to understand, interpret, and generate human language.  It uses techniques from machine learning, deep learning, and linguistics.\n",
      "    *   **Text analysis:** Sentiment analysis (determining the emotion expressed in text), topic modeling (identifying the main themes in a collection of documents), and named entity recognition (identifying people, organizations, and locations).\n",
      "    *   **Machine translation:** Translating text from one language to another.\n",
      "    *   **Chatbots:**  AI programs that can simulate conversations with humans.\n",
      "    *   **Text generation:**  Creating new text, such as articles, poems, or code.\n",
      "\n",
      "*   **Computer Vision:**  This enables computers to \"see\" and interpret images and videos.\n",
      "    *   **Image recognition:** Identifying objects in an image.\n",
      "    *   **Object detection:** Locating and identifying multiple objects in an image.\n",
      "    *   **Image segmentation:** Dividing an image into different regions.\n",
      "    *   **Facial recognition:** Identifying people in images or videos.\n",
      "\n",
      "*   **Robotics:**  This involves designing, constructing, operating, and applying robots.  AI is used to control robots and enable them to perform tasks autonomously.\n",
      "    *   **Navigation:**  Enabling robots to move around in their environment.\n",
      "    *   **Manipulation:**  Enabling robots to grasp and manipulate objects.\n",
      "    *   **Human-robot interaction:**  Enabling robots to interact with humans in a natural way.\n",
      "\n",
      "**5. The AI Development Process (Simplified)**\n",
      "\n",
      "While the specifics vary depending on the project, a typical AI development process might look like this:\n",
      "\n",
      "1.  **Define the Problem:** What task do you want the AI to perform?\n",
      "2.  **Gather Data:** Collect a large dataset relevant to the task.\n",
      "3.  **Prepare Data:** Clean and preprocess the data to make it suitable for training.\n",
      "4.  **Choose a Model:** Select the appropriate AI algorithm or model for the task (e.g., a CNN for image recognition, an RNN for text generation).\n",
      "5.  **Train the Model:** Feed the data to the model and let it learn the patterns.  This often involves adjusting the model's parameters to minimize errors.\n",
      "6.  **Evaluate the Model:** Test the model on a separate dataset to assess its performance.\n",
      "7.  **Deploy the Model:** Put the model into production so that it can be used to solve the problem.\n",
      "8.  **Monitor and Improve:** Continuously monitor the model's performance and retrain it with new data to improve its accuracy over time.\n",
      "\n",
      "**6. Challenges and Limitations**\n",
      "\n",
      "AI, while powerful, still faces significant challenges:\n",
      "\n",
      "*   **Data Requirements:**  Many AI techniques, especially deep learning, require massive amounts of data.\n",
      "*   **Bias:**  AI models can inherit biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n",
      "*   **Explainability:**  Deep learning models are often \"black boxes,\" making it difficult to understand why they make certain decisions. This lack of transparency can be problematic in sensitive applications.\n",
      "*   **Adversarial Attacks:**  AI models can be tricked by carefully crafted inputs (adversarial examples) that cause them to make incorrect predictions.\n",
      "*   **Ethical Concerns:**  AI raises many ethical concerns, such as job displacement, privacy violations, and the potential for misuse.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "AI is a broad field that aims to create machines that can perform tasks requiring human intelligence. It achieves this through algorithms and data, using techniques like machine learning, deep learning, and natural language processing. While AI has made significant progress, it still faces challenges related to data requirements, bias, explainability, and ethical considerations.  It's an evolving field with a lot of potential, but also requires careful consideration and responsible development.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "df=pd.read_csv(\"umair_done_updated.csv\")\n",
    "dates=df['date_and_time']\n",
    "client = genai.Client(api_key=\"AIzaSyCU83BvJPmptqq3h1NhKaQfVkV7aWcmaXE\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Explain how AI works\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
